{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f3e238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef70e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000164BCCD4FA0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000164BCCD5DE0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\", api_key=api_key)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceddcd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed8a2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_powered_autonous_agent = \"\"\"\n",
    "The article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the development and capabilities of autonomous agents powered by large language models (LLMs). It outlines a system architecture that includes three main components: Planning, Memory, and Tool Use. \n",
    "\n",
    "1. **Planning** involves task decomposition, where complex tasks are broken down into manageable subgoals, and self-reflection, allowing agents to learn from past actions to improve future performance. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are highlighted for enhancing reasoning and planning.\n",
    "\n",
    "2. **Memory** is categorized into short-term and long-term memory, with mechanisms for fast retrieval using Maximum Inner Product Search (MIPS) algorithms. This allows agents to retain and recall information effectively.\n",
    "\n",
    "3. **Tool Use** enables agents to interact with external APIs and tools, enhancing their capabilities beyond the limitations of their training data. Examples include MRKL systems and frameworks like HuggingGPT, which facilitate task planning and execution.\n",
    "\n",
    "The article also addresses challenges such as finite context length, difficulties in long-term planning, and the reliability of natural language interfaces. It concludes with case studies demonstrating the practical applications of these concepts in scientific discovery and interactive simulations. Overall, the article emphasizes the potential of LLMs as powerful problem solvers in autonomous agent systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf57fe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the development and capabilities of autonomous agents powered by large language models (LLMs). It outlines a system architecture that includes three main components: Planning, Memory, and Tool Use. \\n\\n1. **Planning** involves task decomposition, where complex tasks are broken down into manageable subgoals, and self-reflection, allowing agents to learn from past actions to improve future performance. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are highlighted for enhancing reasoning and planning.\\n\\n2. **Memory** is categorized into short-term and long-term memory, with mechanisms for fast retrieval using Maximum Inner Product Search (MIPS) algorithms. This allows agents to retain and recall information effectively.\\n\\n3. **Tool Use** enables agents to interact with external APIs and tools, enhancing their capabilities beyond the limitations of their training data. Examples include MRKL systems and frameworks like HuggingGPT, which facilitate task planning and execution.\\n\\nThe article also addresses challenges such as finite context length, difficulties in long-term planning, and the reliability of natural language interfaces. It concludes with case studies demonstrating the practical applications of these concepts in scientific discovery and interactive simulations. Overall, the article emphasizes the potential of LLMs as powerful problem solvers in autonomous agent systems.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_powered_autonous_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b683f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages = [\n",
    "    SystemMessage(content=\"You are an expert in summarizing articles.\"),\n",
    "    HumanMessage(content=\"Please provide a short and consise summary of the article: \" + LLM_powered_autonous_agent)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f90381f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(LLM_powered_autonous_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7499895",
   "metadata": {},
   "source": [
    "One way of creating summary is :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "850a1f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lilian Weng\\'s \"LLM Powered Autonomous Agents\" explores how Large Language Models (LLMs) are enabling the creation of sophisticated autonomous agents. \\n\\nThese agents leverage three key components:\\n\\n* **Planning:** LLMs break down complex tasks into smaller steps, learn from past actions, and use techniques like Chain of Thought to improve decision-making.\\n* **Memory:**  Both short-term and long-term memory are employed, with efficient retrieval mechanisms allowing agents to access and recall information effectively.\\n* **Tool Use:**  Agents can interact with external APIs and tools, expanding their capabilities beyond their training data.\\n\\nThe article highlights the potential of this technology while acknowledging challenges like limited context length and the need for more reliable natural language interfaces. Case studies demonstrate the practical applications of LLM-powered agents in scientific discovery and interactive simulations, solidifying their potential as powerful problem solvers. \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary1 = llm(chat_messages).content\n",
    "summary1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e38a26",
   "metadata": {},
   "source": [
    "if we want to see the AI message then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df84542d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This article explores the development of autonomous agents driven by large language models (LLMs).  These agents are designed with three key components:\\n\\n* **Planning:**  LLMs break down complex tasks into smaller steps and learn from past actions to improve future performance. Techniques like Chain of Thought and Tree of Thoughts are used to enhance reasoning.\\n* **Memory:** \\nShort-term and long-term memory systems allow agents to effectively store and recall information.\\n* **Tool Use:** Agents can interact with external APIs and tools, expanding their capabilities beyond their training data.  Examples include MRKL systems and HuggingGPT.\\n\\nWhile promising, challenges remain such as limited context length, difficulties with long-term planning, and the reliability of natural language interfaces.  Despite these hurdles, the article showcases the potential of LLMs to revolutionize problem-solving in autonomous agents through case studies in scientific discovery and interactive simulations.  \\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 189, 'prompt_tokens': 299, 'total_tokens': 488, 'completion_time': 0.343636364, 'prompt_time': 0.01116621, 'queue_time': 0.260390817, 'total_time': 0.354802574}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4b485650-cd2e-46fc-89dd-e458588adcc1-0', usage_metadata={'input_tokens': 299, 'output_tokens': 189, 'total_tokens': 488})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(chat_messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e9991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80690762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(summary1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0548adb0",
   "metadata": {},
   "source": [
    "#### 2nd way: Prompt Template Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11260bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['LLM_powered_autonous_agent', 'langauge'], input_types={}, partial_variables={}, template='\\nWrite a summary of the following article:\\nArticle: {LLM_powered_autonous_agent}\\nTranslate the precise summary to {langauge}\\n')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "Generictemplate = \"\"\"\n",
    "Write a summary of the following article:\n",
    "Article: {LLM_powered_autonous_agent}\n",
    "Translate the precise summary to {langauge}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['LLM_powered_autonous_agent', 'langauge'],\n",
    "    template=Generictemplate\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3db1edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite a summary of the following article:\\nArticle: \\nThe article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the development and capabilities of autonomous agents powered by large language models (LLMs). It outlines a system architecture that includes three main components: Planning, Memory, and Tool Use. \\n\\n1. **Planning** involves task decomposition, where complex tasks are broken down into manageable subgoals, and self-reflection, allowing agents to learn from past actions to improve future performance. Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are highlighted for enhancing reasoning and planning.\\n\\n2. **Memory** is categorized into short-term and long-term memory, with mechanisms for fast retrieval using Maximum Inner Product Search (MIPS) algorithms. This allows agents to retain and recall information effectively.\\n\\n3. **Tool Use** enables agents to interact with external APIs and tools, enhancing their capabilities beyond the limitations of their training data. Examples include MRKL systems and frameworks like HuggingGPT, which facilitate task planning and execution.\\n\\nThe article also addresses challenges such as finite context length, difficulties in long-term planning, and the reliability of natural language interfaces. It concludes with case studies demonstrating the practical applications of these concepts in scientific discovery and interactive simulations. Overall, the article emphasizes the potential of LLMs as powerful problem solvers in autonomous agent systems.\\n\\nTranslate the precise summary to German\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_prompt = prompt.format(LLM_powered_autonous_agent=LLM_powered_autonous_agent, langauge=\"German\")\n",
    "complete_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa8f2e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(complete_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6fb1a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Der Artikel \"LLM Powered Autonomous Agents\" von Lilian Weng behandelt die Entwicklung und Möglichkeiten autonomer Agenten, die von großen Sprachmodellen (LLMs) angetrieben werden. Er skizziert eine Systemarchitektur mit drei Hauptkomponenten: Planung, Speicher und Werkzeugnutzung.\\n\\n1. **Planung** umfasst die Aufgabenzerlegung, bei der komplexe Aufgaben in überschaubare Teilziele unterteilt werden, sowie Selbstreflexion, die es den Agenten ermöglicht, aus früheren Handlungen zu lernen und ihre zukünftige Leistung zu verbessern. Techniken wie Chain of Thought (CoT) und Tree of Thoughts (ToT) werden hervorgehoben, um das Schlussfolgern und Planen zu verbessern.\\n\\n2. **Speicher** gliedert sich in Kurzzeit- und Langzeitgedächtnis, mit Mechanismen für eine schnelle Abrufbarkeit mithilfe von Maximum Inner Product Search (MIPS)-Algorithmen. Dadurch können Agenten Informationen effektiv speichern und abrufen.\\n\\n3. **Werkzeugnutzung** ermöglicht es den Agenten, mit externen APIs und Werkzeugen zu interagieren, wodurch ihre Fähigkeiten über die Grenzen ihrer Trainingsdaten hinaus erweitert werden. Beispiele sind MRKL-Systeme und Frameworks wie HuggingGPT, die die Aufgabenplanung und -ausführung erleichtern.\\n\\nDer Artikel behandelt auch Herausforderungen wie die endliche Kontextlänge, Schwierigkeiten bei der Langzeitplanung und die Zuverlässigkeit von Natural Language Interfaces. Abschließend werden Fallstudien vorgestellt, die die praktischen Anwendungen dieser Konzepte in der wissenschaftlichen Entdeckung und interaktiven Simulationen demonstrieren. Insgesamt betont der Artikel das Potenzial von LLMs als leistungsstarke Problemlöser in autonomen Agentensystemen. \\n\\n\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "summary = llm_chain.run({'LLM_powered_autonous_agent': LLM_powered_autonous_agent, 'langauge':\"German\"})\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf69d21f",
   "metadata": {},
   "source": [
    "### types To Discuss\n",
    "1. #### StuffDocumentChain Text summarization technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365c95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
